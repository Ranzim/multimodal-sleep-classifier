{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚ö†Ô∏è IMPORTANT: NEW VERSION DETECTED (3 MODELS IMPLEMENTED)\n",
    "**If you are seeing only 2 models, please refresh this page (or reopen this file).**\n",
    "\n",
    "This version contains:\n",
    "1. **Logistic Regression**\n",
    "2. **Random Forest**\n",
    "3. **Decision Tree**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sleep Disorder Classification Project\n",
    "\n",
    "**Course:** Data Science Final Project  \n",
    "**Dataset:** Sleep Health and Lifestyle (374 samples, 13 features)  \n",
    "**link:** https://www.kaggle.com/datasets/uom190346a/sleep-health-and-lifestyle-dataset\n",
    "\n",
    "**Goal:** Predict sleep disorders (None, Insomnia, Sleep Apnea) from health and lifestyle data  \n",
    "**Problem Type:** Multi-class Classification (3 classes)  \n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "This analysis uses machine learning to predict sleep disorders based on:\n",
    "- Demographics (age, gender, occupation)\n",
    "- Sleep patterns (duration, quality)\n",
    "- Health metrics (BMI, blood pressure, heart rate)\n",
    "- Lifestyle factors (physical activity, stress level, daily steps)\n",
    "\n",
    "**Key Feature:** Uses **Pipeline** for professional, production-ready preprocessing workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# STEP 1: Setup & Data Loading\n",
    "\n",
    "**What this step does:**\n",
    "- Import necessary libraries for data analysis and machine learning\n",
    "- Load the Sleep Health dataset from CSV file\n",
    "- Display basic information about the dataset (shape, columns, first rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.14.2' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"‚úì All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('Sleep_health_and_lifestyle_dataset.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"\\nColumn Names:\\n{df.columns.tolist()}\")\n",
    "print(f\"\\nFirst 5 Rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# STEP 2: Exploratory Data Analysis (EDA)\n",
    "\n",
    "**What this step does:**\n",
    "- Check for missing values in the dataset\n",
    "- Visualize target variable distribution (Sleep Disorder)\n",
    "- Explore numeric features with histograms\n",
    "- Analyze correlations between features\n",
    "- Compare features across different sleep disorder categories\n",
    "\n",
    "**Key insights to find:**\n",
    "- Are classes balanced or imbalanced?\n",
    "- Which features show strong patterns?\n",
    "- Are there correlations between features?\n",
    "- Do features differ significantly across disorder types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "print(\"Missing Values Summary:\")\n",
    "missing = df.isnull().sum()\n",
    "print(missing[missing > 0])\n",
    "print(f\"\\nNote: {df['Sleep Disorder'].isnull().sum()} NaN values in 'Sleep Disorder' represent 'None' (no disorder)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "models = [(lr_best, 'Logistic Regression', 'Blues', 0), (rf_best, 'Random Forest', 'Greens', 1), (dt_best, 'Decision Tree', 'Oranges', 2)]\n",
    "\n",
    "for model, name, col, idx in models:\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=col, ax=axes[idx], xticklabels=le_target.classes_, yticklabels=le_target.classes_)\n",
    "    axes[idx].set_title(f\"{name}\\nAcc: {accuracy_score(y_test, y_pred):.4f}\", fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize numeric features\n",
    "numeric_cols = ['Age', 'Sleep Duration', 'Quality of Sleep', 'Physical Activity Level', \n",
    "                'Stress Level', 'Heart Rate', 'Daily Steps']\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(numeric_cols):\n",
    "    df[col].hist(bins=15, ax=axes[idx], color='lightblue', edgecolor='black')\n",
    "    axes[idx].set_title(col, fontsize=10, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Frequency', fontsize=8)\n",
    "\n",
    "fig.delaxes(axes[7])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚Üí Most features show reasonable distributions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "numeric_df = df[numeric_cols].copy()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(numeric_df.corr(), annot=True, fmt='.2f', cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix of Numeric Features', fontweight='bold', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚Üí Quality of Sleep and Sleep Duration are positively correlated\")\n",
    "print(\"‚Üí Stress Level negatively correlates with sleep quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare numeric features by disorder type\n",
    "numeric_features = ['Age', 'Sleep Duration', 'Quality of Sleep', \n",
    "                     'Physical Activity Level', 'Stress Level', \n",
    "                     'Heart Rate', 'Daily Steps']\n",
    "\n",
    "# Create 2√ó4 subplot grid\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 6))\n",
    "\n",
    "# Plot numeric features\n",
    "for idx, col in enumerate(numeric_features):\n",
    "    row, col_idx = divmod(idx, 4)\n",
    "    sns.boxplot(data=df, x='Sleep Disorder', y=col, ax=axes[row, col_idx], \n",
    "            hue='Sleep Disorder', palette='Set2', legend=False)\n",
    "    axes[row, col_idx].set_title(col, fontweight='bold', fontsize=10)\n",
    "    axes[row, col_idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Remove empty subplot\n",
    "fig.delaxes(axes[1, 3])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚Üí Numeric features compared by sleep disorder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How categorical features relate to sleep disorders\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "sns.countplot(data=df, x='Gender', hue='Sleep Disorder', ax=axes[0])\n",
    "sns.countplot(data=df, x='BMI Category', hue='Sleep Disorder', ax=axes[1])\n",
    "sns.countplot(data=df, x='Occupation', hue='Sleep Disorder', ax=axes[2])\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# STEP 3: Data Preparation\n",
    "\n",
    "## 3.1 Handle Missing Values\n",
    "\n",
    "**What this step does:**\n",
    "- Fill NaN values in 'Sleep Disorder' column with \"None\" (represents no disorder)\n",
    "- Keep all 374 rows instead of dropping data\n",
    "\n",
    "**Why fill instead of drop:**\n",
    "- NaN doesn't mean missing data - it means person has no sleep disorder\n",
    "- Dropping would lose 219 rows (58% of dataset!)\n",
    "- More data = better model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clean copy and fill NaN\n",
    "df_clean = df.copy()\n",
    "df_clean['Sleep Disorder'].fillna('None', inplace=True)\n",
    "\n",
    "print(f\"Before: {df.shape[0]} rows\")\n",
    "print(f\"After filling NaN: {df_clean.shape[0]} rows\")\n",
    "print(f\"\\nNew Target Distribution:\")\n",
    "print(df_clean['Sleep Disorder'].value_counts())\n",
    "print(\"\\n‚úì All data preserved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Feature Engineering\n",
    "\n",
    "**What this step does:**\n",
    "- Split Blood Pressure into 3 components (Systolic, Diastolic, Pulse Pressure)\n",
    "- Create Stress-Sleep Risk (interaction term)\n",
    "- Convert BMI to numeric scale\n",
    "\n",
    "**Why create these features:**\n",
    "- **Blood Pressure Split**: Medical insight - systolic/diastolic have different meanings\n",
    "- **Stress-Sleep Risk**: Captures combined effect (high stress + low sleep = high risk)\n",
    "- **BMI Numeric**: Preserves ordering (Normal < Overweight < Obese)\n",
    "\n",
    "**Result:** 3 new features give model more information to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split Blood Pressure (\"120/80\" ‚Üí Systolic, Diastolic, Pulse Pressure)\n",
    "\n",
    "df_clean[['Systolic_BP', 'Diastolic_BP']] = df_clean['Blood Pressure'].str.split('/', expand=True).astype(int)\n",
    "df_clean['Pulse_Pressure'] = df_clean['Systolic_BP'] - df_clean['Diastolic_BP']\n",
    "df_clean.drop('Blood Pressure', axis=1, inplace=True)\n",
    "print(\"‚úì Created: Systolic_BP, Diastolic_BP, Pulse_Pressure\")\n",
    "\n",
    "# 2. Stress-Sleep Risk (interaction term)\n",
    "df_clean['Stress_Sleep_Risk'] = df_clean['Stress Level'] * (10 - df_clean['Sleep Duration'])\n",
    "print(\"‚úì Created: Stress_Sleep_Risk\")\n",
    "\n",
    "# 3. BMI Numeric\n",
    "bmi_map = {'Normal': 0, 'Normal Weight': 0, 'Overweight': 1, 'Obese': 2}\n",
    "df_clean['BMI_Numeric'] = df_clean['BMI Category'].map(bmi_map)\n",
    "print(\"‚úì Created: BMI_Numeric\")\n",
    "\n",
    "print(f\"\\nTotal features now: {df_clean.shape[1]}\")\n",
    "print(\"‚Üí 3 new features added to help model learn better patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Encode Target Variable & Prepare for Pipeline\n",
    "\n",
    "**What this step does:**\n",
    "- Encode target variable (Sleep Disorder) using LabelEncoder\n",
    "- Identify numeric and categorical features for Pipeline\n",
    "- Define feature lists that will be used by ColumnTransformer\n",
    "\n",
    "**Why encode target separately:**\n",
    "- Target encoding happens before Pipeline (Pipeline handles features only)\n",
    "- Need numeric target for classification algorithms\n",
    "- Example: \"None\" ‚Üí 0, \"Insomnia\" ‚Üí 1, \"Sleep Apnea\" ‚Üí 2\n",
    "\n",
    "**Pipeline preparation:**\n",
    "- Numeric features will be scaled with StandardScaler\n",
    "- Categorical features will be one-hot encoded\n",
    "- Pipeline automates this in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target variable\n",
    "le_target = LabelEncoder()\n",
    "y_encoded = le_target.fit_transform(df_clean['Sleep Disorder'])\n",
    "\n",
    "print(\"Target Encoding:\")\n",
    "for i, class_name in enumerate(le_target.classes_):\n",
    "    print(f\"  {class_name} ‚Üí {i}\")\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = ['Age', 'Sleep Duration', 'Quality of Sleep', \n",
    "                   'Physical Activity Level', 'Stress Level', \n",
    "                   'Heart Rate', 'Daily Steps', 'Systolic_BP', \n",
    "                   'Diastolic_BP', 'Pulse_Pressure', 'Stress_Sleep_Risk', 'BMI_Numeric']\n",
    "\n",
    "categorical_features = ['Gender', 'Occupation', 'BMI Category']\n",
    "\n",
    "print(f\"\\n‚úì Identified {len(numeric_features)} numeric features\")\n",
    "print(f\"‚úì Identified {len(categorical_features)} categorical features\")\n",
    "print(\"\\n‚Üí Ready for Pipeline preprocessing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Train-Test Split\n",
    "\n",
    "**What this step does:**\n",
    "- Separate features (X) from target variable (y)\n",
    "- Remove non-predictive column (Person ID)\n",
    "- Split data into training set (80%) and test set (20%)\n",
    "- Use stratified split to maintain class proportions\n",
    "\n",
    "**Why 80-20 split:**\n",
    "- 80% (299 samples) provides enough data for training\n",
    "- 20% (75 samples) provides reliable performance evaluation\n",
    "- Standard practice in machine learning\n",
    "\n",
    "**Why stratified:**\n",
    "- Our classes are imbalanced (more \"None\" than disorders)\n",
    "- Stratification ensures test set represents all classes fairly\n",
    "- Without it, test set might randomly have too few of one class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_clean.drop(columns=['Sleep Disorder', 'Person ID'])\n",
    "y = df_clean['Sleep Disorder']\n",
    "\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "\n",
    "# Split 80-20 with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nTrain class distribution: {pd.Series(y_train).value_counts().sort_index().tolist()}\")\n",
    "print(f\"Test class distribution: {pd.Series(y_test).value_counts().sort_index().tolist()}\")\n",
    "print(\"\\n‚Üí Classes are balanced across train and test sets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Create Preprocessing Pipeline üîß\n",
    "\n",
    "**What this step does:**\n",
    "- Create ColumnTransformer to handle numeric and categorical features separately\n",
    "- Numeric features: Apply StandardScaler (mean=0, std=1)\n",
    "- Categorical features: Apply OneHotEncoder (create binary columns)\n",
    "- Bundle preprocessing into reusable pipeline component\n",
    "\n",
    "### **1. Prevents Data Leakage Automatically** \n",
    "- Manual: Must remember to `fit_transform(train)` and only `transform(test)`\n",
    "- Pipeline: Automatically handles this correctly every time\n",
    "- Risk of accidentally fitting on test data = eliminated\n",
    "\n",
    "### **2. Reproducible & Reusable** \n",
    "- Save entire pipeline with model\n",
    "- Apply same preprocessing to new data automatically\n",
    "- No risk of forgetting preprocessing steps\n",
    "\n",
    "### **3. Easier Integration with GridSearchCV** \n",
    "- Can tune preprocessing parameters alongside model parameters\n",
    "- Everything happens in one cross-validation loop\n",
    "- More efficient and less error-prone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not specified\n",
    ")\n",
    "\n",
    "print(\"‚úì Preprocessing Pipeline Created\")\n",
    "print(\"\\nPipeline Components:\")\n",
    "print(f\"  1. StandardScaler ‚Üí {len(numeric_features)} numeric features\")\n",
    "print(f\"  2. OneHotEncoder ‚Üí {len(categorical_features)} categorical features\")\n",
    "print(\"\\n‚Üí Pipeline will automatically fit on training data and transform both train and test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# STEP 4: Modeling (Logistic Regression, Random Forest, Decision Tree)\n",
    "\n",
    "**What this step does:**\n",
    "- Create 3 distinct machine learning pipelines\n",
    "- Compare performance using 5-Fold Cross-Validation\n",
    "- Perform GridSearchCV for hyperparameter tuning\n",
    "\n",
    "**Why this is important:**\n",
    "- Logistic Regression provides a stable linear baseline\n",
    "- Random Forest handles complex patterns and outliers\n",
    "- Decision Tree offers clear, simple decision rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 4.1 Define the 3 Pipelines\n",
    "lr_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=200))\n",
    "])\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "dt_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipelines = {\n",
    "    'Logistic Regression': lr_pipeline,\n",
    "    'Random Forest': rf_pipeline,\n",
    "    'Decision Tree': dt_pipeline\n",
    "}\n",
    "print('‚úì 3 Pipelines (LR, RF, DT) created successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Cross-Validation Comparison for ALL 3 Models\n",
    "print('5-Fold Cross-Validation Scores (Accuracy):')\n",
    "print('-' * 45)\n",
    "\n",
    "for name, pipe in pipelines.items():\n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv=5)\n",
    "    print(f'{name:20}: {scores.mean():.4f} (+/- {scores.std():.4f})')\n",
    "\n",
    "# Plot for all 3\n",
    "plt.figure(figsize=(10, 4))\n",
    "means = [cross_val_score(pipe, X_train, y_train, cv=5).mean() for pipe in pipelines.values()]\n",
    "plt.bar(pipelines.keys(), means, color=['skyblue', 'lightgreen', 'salmon'], edgecolor='black')\n",
    "plt.title('Comparison of 3 Models (CV Accuracy)', fontweight='bold')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.ylim(0.8, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Hyperparameter Tuning for ALL 3 Models\n",
    "print('Tuning Hyperparameters for 3 models...')\n",
    "\n",
    "lr_grid = GridSearchCV(lr_pipeline, {'classifier__C': [0.1, 1, 10]}, cv=5).fit(X_train, y_train)\n",
    "rf_grid = GridSearchCV(rf_pipeline, {'classifier__n_estimators': [100, 200], 'classifier__max_depth': [10, None]}, cv=5).fit(X_train, y_train)\n",
    "dt_grid = GridSearchCV(dt_pipeline, {'classifier__max_depth': [5, 10, None]}, cv=5).fit(X_train, y_train)\n",
    "\n",
    "# Define best estimators immediately to avoid name errors\n",
    "lr_best = lr_grid.best_estimator_\n",
    "rf_best = rf_grid.best_estimator_\n",
    "dt_best = dt_grid.best_estimator_\n",
    "\n",
    "print(f'Best LR Score: {lr_grid.best_score_:.4f}')\n",
    "print(f'Best RF Score: {rf_grid.best_score_:.4f}')\n",
    "print(f'Best DT Score: {dt_grid.best_score_:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# STEP 5: Model Evaluation & Feature Importance\n",
    "\n",
    "**What this step does:**\n",
    "- Visualize accuracy using 3 Parallel Confusion Matrices\n",
    "- Generate detailed classification reports\n",
    "- Calculate Feature Importance for Tree models\n",
    "\n",
    "**Why this is important:**\n",
    "- Helps identify which specific sleep disorders are being misclassified\n",
    "- Shows which lifestyle factors are the strongest predictors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Reports for all 3 models\n",
    "for model, name, _, _ in final_models:\n",
    "    print(f\"\\n{name} - Classification Report:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(classification_report(y_test, model.predict(X_test), target_names=le_target.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Summary & Final Conclusions\n",
    "\n",
    "### 1. Model Comparison Overview\n",
    "Through this multi-class classification project, we evaluated three distinct algorithms using a professional pipeline workflow. \n",
    "\n",
    "| Model | Accuracy (Test) | Strengths |\n",
    "| :--- | :--- | :--- |\n",
    "| **Logistic Regression** | **~94.67%** | Most consistent performance and simple for deployment. |\n",
    "| **Random Forest** | **~94.67%** | Robust ensemble performance with high accuracy. |\n",
    "| **Decision Tree** | **~89.33%** | Highly interpretable, though slightly lower accuracy. |\n",
    "\n",
    "**Final Choice:** Due to its excellent balance of accuracy, speed, and cross-validation stability, the **Logistic Regression Pipeline** remains the recommended model for this dataset.\n",
    "\n",
    "### 2. Key Discovery: Medical Predictors\n",
    "The comparison of **Random Forest** and **Decision Tree** feature importance confirms that:\n",
    "1. **BMI_Numeric:** Is the most critical factor for identifying Sleep Apnea.\n",
    "2. **Blood Pressure (Systolic/Diastolic):** Our engineered split features were among the top 5 across all models.\n",
    "3. **Sleep Quality vs duration:** Both models agreed that the *quality* of sleep is often more predictive of a disorder than simple *duration*.\n",
    "\n",
    "### 3. Workflow Success\n",
    "- The **Pipeline Architecture** allowed us to swap between 3 different models instantly while ensuring zero data leakage.\n",
    "- **Hyperparameter Tuning** optimized each algorithm to its highest potential on this specific dataset.\n",
    "\n",
    "### 4. Limitations & Next Steps\n",
    "- **Expand Data:** Collect more samples to better represent the 'Insomnia' and 'Sleep Apnea' groups.\n",
    "- **Deployment:** Use the provided `.joblib` artifacts to build a real-time prediction service.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
